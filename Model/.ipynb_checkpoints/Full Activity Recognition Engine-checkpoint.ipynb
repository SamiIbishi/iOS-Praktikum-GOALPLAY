{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (1) Import all relevant libraries, layer and classes <h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Python libraries\n",
    "import numpy as np, collections\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras\n",
    "import keras.backend as k\n",
    "from keras import optimizers\n",
    "from keras import losses, regularizers\n",
    "from keras import initializers\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# CoreML \n",
    "import coremltools\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# Seaborn\n",
    "import seaborn as sn\n",
    "\n",
    "# Locale methods and properties\n",
    "from model import create_model\n",
    "from callbacks import get_callbacks \n",
    "from auxilary_functions import time_stamp\n",
    "from load_data import load_and_store_data, load_stored_data \n",
    "from data_augmentation import normalize_data, standardize_data\n",
    "from plot_pose_sequence import plot_trainings_data, plot_test_data\n",
    "from plot_confusion_matrix import print_confusion_matrix \n",
    "from plot_trainings_history import plot_loss_acc\n",
    "from plot_data_distribution import plot_data_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (2) Load and prepare goalkeeper pose data <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"./stored_data/4_classes/\"\n",
    "\n",
    "# Load data from .npy files \n",
    "# (Framrates/Poses-per-sequence: '5' / '10' / '15' / '30' / '45' / '60' / '75' / '90')\n",
    "#X_raw, y_raw = load_stored_data(dir_path=DATA_PATH, num_poses='90')\n",
    "#data_augmentation = \"\"\n",
    "#range_mean=(0,0)\n",
    "#range_std=(0,0)\n",
    "# X = [samples, timesteps, features]\n",
    "# y = [samples, labels]\n",
    "X_raw, y_raw = load_and_store_data(num_poses=75, X_filename_prefix='X_data_75p', y_filename_prefix='y_data_75p')\n",
    "\n",
    "# Augment data\n",
    "X, y, range_mean, range_std, data_augmentation = standardize_data(X_raw, y_raw)\n",
    "#X, y, data_augmentation = normalize_data(X_raw, y_raw)\n",
    "\n",
    "# Split dataset into train and test set (and shuffle them)\n",
    "X_train, X_test, y_train_temp, y_test_temp = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
    "\n",
    "# Classes\n",
    "num_classes = 4 # n classes (should go up, or should go down)\n",
    "\n",
    "# Get one hot vector from labels\n",
    "y_train = to_categorical(y_train_temp, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test_temp, num_classes=num_classes)\n",
    "\n",
    "# Input features\n",
    "INPUT = [\n",
    "    \"HEAD_X\",\n",
    "    \"HEAD_Y_\",\n",
    "    \"BODY_X\",\n",
    "    \"BODY_Y\",\n",
    "    \"LEFT_ARM_X\",\n",
    "    \"LEFT_ARM_Y\",\n",
    "    \"RIGHT_ARM_X\",\n",
    "    \"RIGHT_ARM_Y\",\n",
    "    \"LEFT_LEG_X\",\n",
    "    \"LEFT_LEG_Y\",\n",
    "    \"RIGHT_LEG_X\",\n",
    "    \"RIGHT_LEG_Y\",\n",
    "]\n",
    "\n",
    "# Output classes\n",
    "LABELS = [    \n",
    "    \"STAND_BY\",\n",
    "    \"LEFT_DIVE\",\n",
    "    \"RIGHT_DIVE\",\n",
    "    \"HIGH_CATCH\",\n",
    "]\n",
    "\n",
    "# Some debugging info\n",
    "print(\"---------------------------------------\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Bsic information regardin the data:\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Trainings data...\")\n",
    "print(\"... input shape=\" + str(X_train.shape))\n",
    "print(\"... target shape=\" + str(y_train.shape))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Test data...\")\n",
    "print(\"... input shape=\" + str(X_test.shape))\n",
    "print(\"... target shape=\" + str(y_test.shape))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data distribution (trainings data)\n",
    "plot_data_distribution(y_train_temp, labels=LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data distribution (teest data)\n",
    "plot_data_distribution(y_test_temp, labels=LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sequence of poses\n",
    "plot_trainings_data(X_train, y_train_temp, sample=25,  data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sequence of poses range_mean, range_std\n",
    "plot_trainings_data(X_train, y_train_temp, sample=845, data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sequence of poses\n",
    "plot_trainings_data(X_train, y_train_temp, sample=103, data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (3) Define constants and additional parameters <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input Data\n",
    "n_timesteps = X_train.shape[1] #len(X_train[1])  # n-timesteps per series per series\n",
    "n_features = X_train.shape[2] #len(X_train[0][0])  # n input parameters per timestep\n",
    "\n",
    "# LSTM Neural Network's internal structure\n",
    "input_shape = (n_timesteps, n_features)\n",
    "n_mem_units = 128 # Hidden layer num of features\n",
    "\n",
    "# Training - Hyperparameter  \n",
    "learning_rate = 0.001\n",
    "optimizer = optimizers.RMSprop(lr=learning_rate, decay=0.5) \n",
    "n_epochs = 30  \n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (4) Define and build sequence model <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_model(input_shape, num_classes=num_classes, dropout=True)\n",
    "\n",
    "# Build model \n",
    "model.compile(loss=losses.categorical_crossentropy, \n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model details/summary\n",
    "model.summary()\n",
    "\n",
    "# Get curent time stamp\n",
    "time_stamp = time_stamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (5) Record and store process of models/training <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "logdir = './training_history/logs/' + time_stamp\n",
    "\n",
    "# Create directory which will contain trained models \n",
    "model_directory = \"./training_history/saved_models/\" + time_stamp\n",
    "\n",
    "# Generate callback list \n",
    "callbacks = get_callbacks(model_directory, logdir, time_stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (6) Train model <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Weight classes to overcome the unbalanced data\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train_temp), y_train_temp)\n",
    "\n",
    "# Reshape model fo CoreML model \n",
    "reshaped_X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "\n",
    "# Train model on trainings data \n",
    "history = model.fit(reshaped_X_train, \n",
    "                    y_train, \n",
    "                    verbose=2, \n",
    "                    shuffle=True, \n",
    "                    epochs=n_epochs, \n",
    "                    validation_split=0.1, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate(reshaped_X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (7) Predict and evaluate <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot history \n",
    "plot_loss_acc(model)\n",
    "\n",
    "# Reshape X_test data\n",
    "reshaped_X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_acc = model.evaluate(reshaped_X_train, y_train, verbose=0)\n",
    "test_acc = model.evaluate(reshaped_X_test, y_test, verbose=0)\n",
    "print(model.metrics_names)\n",
    "print('Train accuracy: ' + str(train_acc))\n",
    "print('Test accuracy: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_classes = model.predict_classes(reshaped_X_test)\n",
    "y_prediction_prob = model.predict(reshaped_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sequence of poses and classify the containing exercises\n",
    "plot_test_data(X_test, y_predicted_classes, y_test_temp, sample=69, data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot one sequence of poses and classify the containing exercises\n",
    "plot_test_data(X_test, y_predicted_classes, y_test_temp, sample=14, data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sequence of poses and classify the containing exercises\n",
    "plot_test_data(X_test, y_predicted_classes, y_test_temp, sample=9, data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (8) Save model <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "saved_model = model_directory + \"/activity_recognition_90fps_model_test_acc_.h5\"\n",
    "model.save(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert trained model into CoreML\n",
    "coreml_model = coremltools.converters.keras.convert(saved_model, \n",
    "                                                    class_labels=LABELS, \n",
    "                                                    input_names=['pose'])\n",
    "\n",
    "# Store CoreML model \n",
    "coreml_model.save(model_directory + \"/activity_recognition_model.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix test data \n",
    "matrix = metrics.confusion_matrix(y_test_temp, y_predicted_classes, labels=np.unique(y_test_temp))\n",
    "print_confusion_matrix(matrix, LABELS, figsize = (14,9), cmap=sn.color_palette(\"Greens\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
