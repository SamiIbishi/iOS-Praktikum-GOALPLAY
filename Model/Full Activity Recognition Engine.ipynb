{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (1) Import all relevant libraries, layer and classes <h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0720 22:40:42.043764 140714437613376 __init__.py:71] TensorFlow version 1.14.0 detected. Last version known to be fully compatible is 1.13.1 .\n",
      "/home/sami/Desktop/iOS-Praktikum-GOALPLAY/Model/plot_trainings_history.py:7: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/home/sami/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/sami/anaconda3/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/sami/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/sami/anaconda3/envs/tf/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/sami/anaconda3/envs/tf/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n",
      "    self.run()\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n",
      "    if (yield from self.run_code(code, result)):\n",
      "  File \"/home/sami/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-7ff9c043d695>\", line 7, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/home/sami/anaconda3/envs/tf/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/home/sami/anaconda3/envs/tf/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('agg')\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Python libraries\n",
    "import numpy as np, collections\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import SVG\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras\n",
    "import keras.backend as k\n",
    "from keras import optimizers\n",
    "from keras import losses, regularizers\n",
    "from keras import initializers\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "# CoreML \n",
    "import coremltools\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# Seaborn\n",
    "import seaborn as sn\n",
    "\n",
    "# Locale methods and properties\n",
    "from model import create_model\n",
    "from callbacks import get_callbacks \n",
    "from auxilary_functions import time_stamp\n",
    "from load_data import load_and_store_data, load_stored_data \n",
    "from data_augmentation import normalize_data, standardize_data\n",
    "from plot_pose_sequence import plot_trainings_data, plot_test_data\n",
    "from plot_confusion_matrix import print_confusion_matrix \n",
    "from plot_trainings_history import plot_loss_acc\n",
    "from plot_data_distribution import plot_data_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (2) Load and prepare goalkeeper pose data <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1327, 5, 26)\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "Bsic information regardin the data:\n",
      "---------------------------------------\n",
      "Trainings data...\n",
      "... input shape=(1194, 5, 26)\n",
      "... target shape=(1194, 4)\n",
      "---------------------------------------\n",
      "Test data...\n",
      "... input shape=(133, 5, 26)\n",
      "... target shape=(133, 4)\n",
      "---------------------------------------\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"./stored_data/4_classes/\"\n",
    "\n",
    "# Load data from .npy files \n",
    "# (Framrates/Poses-per-sequence: '5' / '10' / '15' / '30' / '45' / '60' / '75' / '90')\n",
    "#X_raw, y_raw = load_stored_data(dir_path=DATA_PATH, num_poses='90')\n",
    "#data_augmentation = \"\"\n",
    "#range_mean=(0,0)\n",
    "#range_std=(0,0)\n",
    "# X = [samples, timesteps, features]\n",
    "# y = [samples, labels]\n",
    "X_raw, y_raw = load_and_store_data(num_poses=5, X_filename_prefix='X_data_5p', y_filename_prefix='y_data_5p')\n",
    "\n",
    "# Augment data\n",
    "X, y, range_mean, range_std, data_augmentation = standardize_data(X_raw, y_raw)\n",
    "#X, y, data_augmentation = normalize_data(X_raw, y_raw)\n",
    "\n",
    "# Split dataset into train and test set (and shuffle them)\n",
    "X_train, X_test, y_train_temp, y_test_temp = train_test_split(X, y, test_size = 0.1, random_state = 42)\n",
    "\n",
    "# Classes\n",
    "num_classes = 4 # n classes (should go up, or should go down)\n",
    "\n",
    "# Get one hot vector from labels\n",
    "y_train = to_categorical(y_train_temp, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test_temp, num_classes=num_classes)\n",
    "\n",
    "# Input features\n",
    "INPUT = [\n",
    "    \"HEAD_X\",\n",
    "    \"HEAD_Y_\",\n",
    "    \"BODY_X\",\n",
    "    \"BODY_Y\",\n",
    "    \"LEFT_ARM_X\",\n",
    "    \"LEFT_ARM_Y\",\n",
    "    \"RIGHT_ARM_X\",\n",
    "    \"RIGHT_ARM_Y\",\n",
    "    \"LEFT_LEG_X\",\n",
    "    \"LEFT_LEG_Y\",\n",
    "    \"RIGHT_LEG_X\",\n",
    "    \"RIGHT_LEG_Y\",\n",
    "]\n",
    "\n",
    "# Output classes\n",
    "LABELS = [    \n",
    "    \"STAND_BY\",\n",
    "    \"LEFT_DIVE\",\n",
    "    \"RIGHT_DIVE\",\n",
    "    \"HIGH_CATCH\",\n",
    "]\n",
    "\n",
    "# Some debugging info\n",
    "print(\"---------------------------------------\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Bsic information regardin the data:\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Trainings data...\")\n",
    "print(\"... input shape=\" + str(X_train.shape))\n",
    "print(\"... target shape=\" + str(y_train.shape))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Test data...\")\n",
    "print(\"... input shape=\" + str(X_test.shape))\n",
    "print(\"... target shape=\" + str(y_test.shape))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data distribution (trainings data)\n",
    "plot_data_distribution(y_train_temp, labels=LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data distribution (teest data)\n",
    "plot_data_distribution(y_test_temp, labels=LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sequence of poses\n",
    "plot_trainings_data(X_train, y_train_temp, sample=25,  data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sequence of poses range_mean, range_std\n",
    "plot_trainings_data(X_train, y_train_temp, sample=845, data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sequence of poses\n",
    "plot_trainings_data(X_train, y_train_temp, sample=103, data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (3) Define constants and additional parameters <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input Data\n",
    "n_timesteps = X_train.shape[1] #len(X_train[1])  # n-timesteps per series per series\n",
    "n_features = X_train.shape[2] #len(X_train[0][0])  # n input parameters per timestep\n",
    "\n",
    "# LSTM Neural Network's internal structure\n",
    "input_shape = (n_timesteps, n_features)\n",
    "n_mem_units = 128 # Hidden layer num of features\n",
    "\n",
    "# Training - Hyperparameter  \n",
    "learning_rate = 0.001\n",
    "optimizer = optimizers.RMSprop(lr=learning_rate, decay=0.5) \n",
    "n_epochs = 30  \n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (4) Define and build sequence model <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = create_model(input_shape, num_classes=num_classes, dropout=True)\n",
    "\n",
    "# Build model \n",
    "model.compile(loss=losses.categorical_crossentropy, \n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model details/summary\n",
    "model.summary()\n",
    "\n",
    "# Get curent time stamp\n",
    "time_stamp = time_stamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (5) Record and store process of models/training <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "logdir = './training_history/logs/' + time_stamp\n",
    "\n",
    "# Create directory which will contain trained models \n",
    "model_directory = \"./training_history/saved_models/\" + time_stamp\n",
    "\n",
    "# Generate callback list \n",
    "callbacks = get_callbacks(model_directory, logdir, time_stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (6) Train model <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Weight classes to overcome the unbalanced data\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train_temp), y_train_temp)\n",
    "\n",
    "# Reshape model fo CoreML model \n",
    "reshaped_X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "\n",
    "# Train model on trainings data \n",
    "history = model.fit(reshaped_X_train, \n",
    "                    y_train, \n",
    "                    verbose=2, \n",
    "                    shuffle=True, \n",
    "                    epochs=n_epochs, \n",
    "                    validation_split=0.1, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=callbacks,\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate(reshaped_X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (7) Predict and evaluate <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot history \n",
    "plot_loss_acc(model)\n",
    "\n",
    "# Reshape X_test data\n",
    "reshaped_X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "# Evaluate the model\n",
    "train_acc = model.evaluate(reshaped_X_train, y_train, verbose=0)\n",
    "test_acc = model.evaluate(reshaped_X_test, y_test, verbose=0)\n",
    "print(model.metrics_names)\n",
    "print('Train accuracy: ' + str(train_acc))\n",
    "print('Test accuracy: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_classes = model.predict_classes(reshaped_X_test)\n",
    "y_prediction_prob = model.predict(reshaped_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sequence of poses and classify the containing exercises\n",
    "plot_test_data(X_test, y_predicted_classes, y_test_temp, sample=69, data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot one sequence of poses and classify the containing exercises\n",
    "plot_test_data(X_test, y_predicted_classes, y_test_temp, sample=14, data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one sequence of poses and classify the containing exercises\n",
    "plot_test_data(X_test, y_predicted_classes, y_test_temp, sample=9, data_augmentation=data_augmentation, range_mean=range_mean, range_std=range_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> (8) Save model <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "saved_model = model_directory + \"/activity_recognition_90fps_model_test_acc_.h5\"\n",
    "model.save(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert trained model into CoreML\n",
    "coreml_model = coremltools.converters.keras.convert(saved_model, \n",
    "                                                    class_labels=LABELS, \n",
    "                                                    input_names=['pose'])\n",
    "\n",
    "# Store CoreML model \n",
    "coreml_model.save(model_directory + \"/activity_recognition_model.mlmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix test data \n",
    "matrix = metrics.confusion_matrix(y_test_temp, y_predicted_classes, labels=np.unique(y_test_temp))\n",
    "print_confusion_matrix(matrix, LABELS, figsize = (14,9), cmap=sn.color_palette(\"Greens\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
